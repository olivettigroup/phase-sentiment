{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aad46eca",
   "metadata": {},
   "source": [
    "# Extracting sentences using MatBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb1f9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from nltk.tokenize.punkt import PunktSentenceTokenizer, PunktParameters\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import Dataset\n",
    "\n",
    "# import warnings\n",
    "# from torch.optim import AdamW\n",
    "# from transformers import get_scheduler\n",
    "# from transformers.utils import logging\n",
    "# import evaluate\n",
    "# from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8a279f",
   "metadata": {},
   "source": [
    "First we load the data. Here, `corpus_all_paragraphs` should be a dictionnary with the dois as keys. Each paper is thus separated. For each entry, the dictionnary should contain a list of paragraphs in the form of dicionnaries with, at least, a 'text' entry.\n",
    "\n",
    "Schematically, the data should looks like this:\n",
    "\n",
    "{\n",
    "\n",
    "doi1: [{'text': \"Some text\"}, {'text': \"Some text\"}, {'text': \"Some text\"}],\n",
    "    \n",
    "doi2: [...],\n",
    "    \n",
    "...\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4aa1cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "with open(\"../data_by_corpus/from_papers_v2/all_paragraphs.json\", 'r') as f:\n",
    "    corpus_all_paragraphs = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e784082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer and MatBERT\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"matbert-base-uncased/\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"matbert-sentence-extraction/\").to(device)\n",
    "\n",
    "# Create custom sentence tokenizer with abbreviations\n",
    "punkt_param = PunktParameters()\n",
    "abbreviation = ['fig', 'al', 'e.g', 'i.e']\n",
    "punkt_param.abbrev_types = set(abbreviation)\n",
    "sentence_tokenizer = PunktSentenceTokenizer(punkt_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cdfc9a",
   "metadata": {},
   "source": [
    "Here we loop over every paper and paragraph and evaluate our MatBERT model on each sentence as tokenized by `sentence_tokenizer`. If the sentence's logit prediction is 1, then we add that to `extracted_sentences`. The latter is a list of dictionnaries with each dict containing the keys `sentences`, `doi`, and `paragraph`. `sentences` is a list of sentences extracted from `paragraph` of the paper with doi `doi`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34761a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_sentences = []\n",
    "\n",
    "all_dois = list(corpus_all_paragraphs.keys())\n",
    "\n",
    "for i, doi in enumerate(all_dois):\n",
    "    for para in corpus_all_paragraphs[doi]:\n",
    "\n",
    "        # To prevent extracting the same paragraph twice\n",
    "        if len(extracted_sentences)>0:\n",
    "            if para['_id'] in [s['paragraph']['_id'] for s in extracted_sentences]:\n",
    "                continue\n",
    "\n",
    "        # Some paragraphs could be empty\n",
    "        if len(para['text'])==0:\n",
    "            continue\n",
    "\n",
    "        # Get all the sentences in the paper\n",
    "        sentences = sentence_tokenizer.tokenize(para['text'])\n",
    "\n",
    "        # Prepare sentences to pass in model (tokenize them)\n",
    "        sent_tok = tokenizer(sentences, padding=True, truncation=True, max_length=512)\n",
    "        sent_tok['sentences'] = sentences\n",
    "        test_data = Dataset.from_dict(sent_tok)\n",
    "        test_data.set_format('torch')\n",
    "        test_dataloader = DataLoader(test_data, batch_size=8)\n",
    "\n",
    "        # Evaluate model\n",
    "        predictions = []\n",
    "        model.eval()\n",
    "        for batch in test_dataloader:\n",
    "            batch_sentences = batch['sentences']\n",
    "            batch = {k: v.to(device) for k, v in batch.items() if torch.is_tensor(v)}\n",
    "            with torch.no_grad():\n",
    "                outputs = model(**batch)\n",
    "\n",
    "            logits = outputs.logits\n",
    "            predictions.extend(torch.argmax(logits, dim=-1).cpu().tolist())\n",
    "\n",
    "        # If we have at least one good sentence, add it/them to list\n",
    "        if sum(predictions)>0:\n",
    "            to_add = {}\n",
    "            to_add['sentences'] = np.array(sentences)[np.array(predictions)==1].tolist()\n",
    "            to_add['doi'] = doi\n",
    "            to_add['paragraph'] = para\n",
    "            extracted_sentences.append(to_add)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71960619",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c5ba62",
   "metadata": {},
   "source": [
    "# Training best BERT model\n",
    "The manually labeled data used for hyperparameter tuning of various BERT models can be found in \"data/manually_labelled_sentences.csv\". Each sentence has a label of either 1 for extraction or 0 for non extraction.£"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1c436b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>extract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cr is repelled strongly yielding a Cr enriched...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This result suggests that the local chemical b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>However, a high fraction of δ′ phase is not fa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Low melting point T- and S-phases affect hot w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The so-called Weldalite series of Al–Cu–Li–Mg–...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2046</th>\n",
       "      <td>The present study involves the experimental ev...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2047</th>\n",
       "      <td>Table 2 shows that the corrosion current densi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2048</th>\n",
       "      <td>This is attributed to the fact that the η'-pha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2049</th>\n",
       "      <td>Mathieu et al.51 suggested that the slower cor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050</th>\n",
       "      <td>Historically, the addition of 10-50 wt% hard m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2051 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  extract\n",
       "0     Cr is repelled strongly yielding a Cr enriched...        0\n",
       "1     This result suggests that the local chemical b...        0\n",
       "2     However, a high fraction of δ′ phase is not fa...        1\n",
       "3     Low melting point T- and S-phases affect hot w...        1\n",
       "4     The so-called Weldalite series of Al–Cu–Li–Mg–...        1\n",
       "...                                                 ...      ...\n",
       "2046  The present study involves the experimental ev...        1\n",
       "2047  Table 2 shows that the corrosion current densi...        0\n",
       "2048  This is attributed to the fact that the η'-pha...        1\n",
       "2049  Mathieu et al.51 suggested that the slower cor...        0\n",
       "2050  Historically, the addition of 10-50 wt% hard m...        0\n",
       "\n",
       "[2051 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"data/manually_labelled_sentences.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a84f82b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "luca-sentiment",
   "language": "python",
   "name": "luca-sentiment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
